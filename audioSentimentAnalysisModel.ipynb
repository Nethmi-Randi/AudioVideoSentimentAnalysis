{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8kWmrhxDMNt+HMmWlYwmG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nethmi-Randi/AudioVideoSentimentAnalysis/blob/main/audioSentimentAnalysisModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbjqx5av_oW3",
        "outputId": "2e5e9ad4-b9e3-4cf1-909b-3feb40903ab6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import librosa.display\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "zip_file_path = '/content/drive/MyDrive/ravdess.zip'\n",
        "\n",
        "import zipfile\n",
        "extract_dir = '/content/MyDrive/RAVDESS/ravdess'\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Process and Organize the dataset and Create data frames"
      ],
      "metadata": {
        "id": "Gx3_3PBpKw76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "Ravdess = '/content/MyDrive/RAVDESS/ravdess/ravdess'\n",
        "\n",
        "ravdess_directory_list = os.listdir(Ravdess)\n",
        "file_emotion = []\n",
        "file_path = []\n",
        "\n",
        "for dir in ravdess_directory_list:\n",
        "    actor = os.listdir(os.path.join(Ravdess, dir))\n",
        "    for file in actor:\n",
        "        part = file.split('.')[0].split('-')\n",
        "        file_emotion.append(int(part[2]))\n",
        "        file_path.append(os.path.join(Ravdess, dir, file))\n",
        "\n",
        "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
        "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
        "ravdess_df = pd.concat([emotion_df, path_df], axis=1)\n",
        "\n",
        "emotion_map = {1: 'neutral', 2: 'calm', 3: 'happy', 4: 'sad', 5: 'angry', 6: 'fear', 7: 'disgust', 8: 'surprise'}\n",
        "ravdess_df.Emotions.replace(emotion_map, inplace=True)\n",
        "\n",
        "# Filter out 'calm' emotion\n",
        "ravdess_df = ravdess_df[ravdess_df.Emotions != 'calm']\n",
        "\n",
        "print(ravdess_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwMJtA6__9rp",
        "outputId": "328c346e-c01d-4629-b5b3-b8aae47407c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Emotions                                               Path\n",
            "0     fear  /content/MyDrive/RAVDESS/ravdess/ravdess/Actor...\n",
            "1     fear  /content/MyDrive/RAVDESS/ravdess/ravdess/Actor...\n",
            "2     fear  /content/MyDrive/RAVDESS/ravdess/ravdess/Actor...\n",
            "3    happy  /content/MyDrive/RAVDESS/ravdess/ravdess/Actor...\n",
            "5    happy  /content/MyDrive/RAVDESS/ravdess/ravdess/Actor...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Augmentation of audio data"
      ],
      "metadata": {
        "id": "LcJnxipwPTmP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def noise(data): # Add random noise to the signal\n",
        "    noise_amp = 0.035 * np.random.uniform() * np.amax(data)\n",
        "    data = data + noise_amp * np.random.normal(size=data.shape[0])\n",
        "    return data\n",
        "\n",
        "def stretch(data, rate=0.8): # Change the speed of the audio without affecting the pitch\n",
        "    return librosa.effects.time_stretch(data, rate)\n",
        "\n",
        "def shift(data): #Shift the audio signal in time\n",
        "    shift_range = int(np.random.uniform(low=-5, high=5) * 1000)\n",
        "    return np.roll(data, shift_range)\n",
        "\n",
        "def pitch(data, sampling_rate, pitch_factor=0.7): #Change the pitch of the audio , without affecting the speed.\n",
        "    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n"
      ],
      "metadata": {
        "id": "lSdylzyLABBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract features from audio"
      ],
      "metadata": {
        "id": "S6py9c5tQ5Rl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(data, sample_rate):\n",
        "    result = np.array([])\n",
        "\n",
        "    # Zero Crossing Rate - The rate at which the signal changes from positive to negative or vice versa\n",
        "    zcr = np.mean(librosa.feature.zero_crossing_rate(y=data).T, axis=0)\n",
        "    result = np.hstack((result, zcr))\n",
        "\n",
        "    # Chroma Shift\n",
        "    stft = np.abs(librosa.stft(data)) #Short-Time Fourier Transform of the audio signal\n",
        "    chroma_stft = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0) #computes the chromagram from the STFT\n",
        "    result = np.hstack((result, chroma_stft))\n",
        "\n",
        "    # MFCC - Coefficients that represent the short-term power spectrum of the sound\n",
        "    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
        "    result = np.hstack((result, mfcc))\n",
        "\n",
        "    # Root Mean Square Value - square root of the average power of the audio signal\n",
        "    rms = np.mean(librosa.feature.rms(y=data).T, axis=0)\n",
        "    result = np.hstack((result, rms))\n",
        "\n",
        "    # MelSpectrogram- spectrogram where the frequencies are converted to the Mel scale\n",
        "    mel = np.mean(librosa.feature.melspectrogram(y=data, sr=sample_rate).T, axis=0)\n",
        "    result = np.hstack((result, mel))\n",
        "\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "MREny5_6ALyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install resampy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GM2Pbr9qBMDv",
        "outputId": "48c6ea69-e761-44c8-d7d0-1d61c291f461",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: resampy in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from resampy) (1.25.2)\n",
            "Requirement already satisfied: numba>=0.53 in /usr/local/lib/python3.10/dist-packages (from resampy) (0.58.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.53->resampy) (0.41.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa resampy\n",
        "import librosa\n",
        "from librosa import display\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ap8OXuFK2oc",
        "outputId": "6cb1dde8-3021-4a07-bcac-37a6cf331a8d",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: resampy in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.58.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa) (24.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (2.31.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install libfluidsynth3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwQS6gsuK2k8",
        "outputId": "923b28f1-bc58-4849-c05b-f5d2fbd9ef48",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libinstpatch-1.0-2 timgm6mb-soundfont\n",
            "Suggested packages:\n",
            "  fluid-soundfont-gm\n",
            "The following NEW packages will be installed:\n",
            "  libfluidsynth3 libinstpatch-1.0-2 timgm6mb-soundfont\n",
            "0 upgraded, 3 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 5,913 kB of archives.\n",
            "After this operation, 7,661 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libinstpatch-1.0-2 amd64 1.1.6-1 [240 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 timgm6mb-soundfont all 1.3-5 [5,427 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libfluidsynth3 amd64 2.2.5-1 [246 kB]\n",
            "Fetched 5,913 kB in 2s (3,236 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libinstpatch-1.0-2:amd64.\n",
            "(Reading database ... 121926 files and directories currently installed.)\n",
            "Preparing to unpack .../libinstpatch-1.0-2_1.1.6-1_amd64.deb ...\n",
            "Unpacking libinstpatch-1.0-2:amd64 (1.1.6-1) ...\n",
            "Selecting previously unselected package timgm6mb-soundfont.\n",
            "Preparing to unpack .../timgm6mb-soundfont_1.3-5_all.deb ...\n",
            "Unpacking timgm6mb-soundfont (1.3-5) ...\n",
            "Selecting previously unselected package libfluidsynth3:amd64.\n",
            "Preparing to unpack .../libfluidsynth3_2.2.5-1_amd64.deb ...\n",
            "Unpacking libfluidsynth3:amd64 (2.2.5-1) ...\n",
            "Setting up timgm6mb-soundfont (1.3-5) ...\n",
            "update-alternatives: using /usr/share/sounds/sf2/TimGM6mb.sf2 to provide /usr/share/sounds/sf2/default-GM.sf2 (default-GM.sf2) in auto mode\n",
            "update-alternatives: using /usr/share/sounds/sf2/TimGM6mb.sf2 to provide /usr/share/sounds/sf3/default-GM.sf3 (default-GM.sf3) in auto mode\n",
            "Setting up libinstpatch-1.0-2:amd64 (1.1.6-1) ...\n",
            "Setting up libfluidsynth3:amd64 (2.2.5-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get -qq install -y graphviz && pip install pydot\n",
        "import pydot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMsz9Q3kLD4y",
        "outputId": "6ab23e3f-a5be-4819-ba05-d9fb934be897",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydot in /usr/local/lib/python3.10/dist-packages (1.4.2)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from pydot) (3.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cartopy\n",
        "import cartopy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ex4Yq3tgLIhX",
        "outputId": "999bfc64-c355-4e43-eedc-3a2e2e80828b",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cartopy\n",
            "  Downloading Cartopy-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from cartopy) (1.25.2)\n",
            "Requirement already satisfied: matplotlib>=3.5 in /usr/local/lib/python3.10/dist-packages (from cartopy) (3.7.1)\n",
            "Requirement already satisfied: shapely>=1.7 in /usr/local/lib/python3.10/dist-packages (from cartopy) (2.0.4)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.10/dist-packages (from cartopy) (24.1)\n",
            "Requirement already satisfied: pyshp>=2.3 in /usr/local/lib/python3.10/dist-packages (from cartopy) (2.3.1)\n",
            "Requirement already satisfied: pyproj>=3.3.1 in /usr/local/lib/python3.10/dist-packages (from cartopy) (3.6.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->cartopy) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->cartopy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->cartopy) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->cartopy) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->cartopy) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->cartopy) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->cartopy) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pyproj>=3.3.1->cartopy) (2024.6.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.5->cartopy) (1.16.0)\n",
            "Installing collected packages: cartopy\n",
            "Successfully installed cartopy-0.23.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install resampy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6iRTUHbLL63",
        "outputId": "77545157-a39a-4c01-af76-63f2f0d4aace",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: resampy in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from resampy) (1.25.2)\n",
            "Requirement already satisfied: numba>=0.53 in /usr/local/lib/python3.10/dist-packages (from resampy) (0.58.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.53->resampy) (0.41.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vz0PZ96gLPVR",
        "outputId": "569416b5-9e5a-4b63-9863-c07a4513960b",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.58.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa) (24.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (2.31.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llvmlite==0.31.0\n",
        "\n",
        "!pip install resampy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WlzmWrHL4pA",
        "outputId": "cea9d0db-a864-4ea7-8918-19c56f7fb781",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llvmlite==0.31.0\n",
            "  Downloading llvmlite-0.31.0.tar.gz (110 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/110.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.8/110.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: llvmlite\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for llvmlite (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for llvmlite\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for llvmlite\n",
            "Failed to build llvmlite\n",
            "\u001b[31mERROR: Could not build wheels for llvmlite, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: resampy in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from resampy) (1.25.2)\n",
            "Requirement already satisfied: numba>=0.53 in /usr/local/lib/python3.10/dist-packages (from resampy) (0.58.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.53->resampy) (0.41.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install resampy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyesG5y7Mnu5",
        "outputId": "34b0e37a-157b-4158-ccf4-035690231fa7",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: resampy in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from resampy) (1.25.2)\n",
            "Requirement already satisfied: numba>=0.53 in /usr/local/lib/python3.10/dist-packages (from resampy) (0.58.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.53->resampy) (0.41.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install resampy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eP_GZb97NToZ",
        "outputId": "bdb8fadb-011b-45a8-c836-45c74c780c40",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: resampy in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from resampy) (1.25.2)\n",
            "Requirement already satisfied: numba>=0.53 in /usr/local/lib/python3.10/dist-packages (from resampy) (0.58.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.53->resampy) (0.41.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa==0.9.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQZdtVcnNXqY",
        "outputId": "d72b6c4f-dd21-4435-cdfe-a2e6ea7a711d",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa==0.9.2 in /usr/local/lib/python3.10/dist-packages (0.9.2)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.2) (3.0.1)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.2) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.2) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.2) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.2) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.2) (4.4.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.2) (0.4.3)\n",
            "Requirement already satisfied: numba>=0.45.1 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.2) (0.58.1)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.2) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.2) (1.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.9.2) (24.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.45.1->librosa==0.9.2) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa==0.9.2) (4.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa==0.9.2) (2.31.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->librosa==0.9.2) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.10.2->librosa==0.9.2) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa==0.9.2) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.2) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.9.2) (2024.7.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import soundfile as sf\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "QS7F5PXlNg9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "librosa.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RtxMIw8qNrlr",
        "outputId": "638f3006-66d4-4781-a225-46ecd22cb8e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.9.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare Audio data\n"
      ],
      "metadata": {
        "id": "S2Xoa_HHh4It"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# lists to hold features and labels\n",
        "x, y = [], []\n",
        "\n",
        "# Iterate over the dataframe to extract features\n",
        "for path, emotion in zip(ravdess_df.Path, ravdess_df.Emotions):\n",
        "    data, sample_rate = librosa.load(path, res_type='kaiser_fast')\n",
        "\n",
        "    features = extract_features(data, sample_rate)\n",
        "\n",
        "    x.append(features)\n",
        "    y.append(emotion)\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "x = np.array(x)\n",
        "y = np.array(y)\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "y = to_categorical(y)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "x = scaler.fit_transform(x)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "x_train, x_temp, y_train, y_temp = train_test_split(x, y, test_size=0.3, random_state=42)\n",
        "x_test, x_val, y_test, y_val = train_test_split(x_temp, y_temp, test_size=(1/3), random_state=42)\n",
        "\n",
        "x_train = np.expand_dims(x_train, axis=2)\n",
        "x_test = np.expand_dims(x_test, axis=2)\n",
        "x_val = np.expand_dims(x_val, axis=2)\n",
        "\n"
      ],
      "metadata": {
        "id": "fpVtkRETAOJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Activation, BatchNormalization\n",
        "\n",
        "# Define input shape\n",
        "input_shape = (x_train.shape[1], 1)\n",
        "\n",
        "# Initialize the model\n",
        "model = Sequential()\n",
        "\n",
        "# Convolutional layers\n",
        "model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu', input_shape=input_shape))\n",
        "model.add(MaxPooling1D(pool_size=5, strides=2, padding='same'))\n",
        "\n",
        "model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=5, strides=2, padding='same'))\n",
        "\n",
        "model.add(Conv1D(128, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=5, strides=2, padding='same'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv1D(128, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
        "model.add(Conv1D(128, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
        "model.add(Conv1D(128, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv1D(64, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
        "model.add(Conv1D(64, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
        "model.add(Flatten())\n",
        "\n",
        "# Dense layers\n",
        "model.add(Dense(units=4096, activation='relu'))\n",
        "model.add(Dense(units=4096, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(units=7, activation='softmax'))\n"
      ],
      "metadata": {
        "id": "RqXofJ7pAQua",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "rlrp = ReduceLROnPlateau(monitor='loss', factor=0.4, verbose=0, patience=2, min_lr=0.0000001)\n",
        "history = model.fit(x_train, y_train, batch_size=32, epochs=75, validation_data=(x_val, y_val), callbacks=[rlrp])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCdrr8dxIZdC",
        "outputId": "3975db83-9c58-4748-fc2b-f189091cae4a",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/75\n",
            "179/179 [==============================] - 40s 127ms/step - loss: 2.0537 - accuracy: 0.2181 - val_loss: 1.8288 - val_accuracy: 0.2514\n",
            "Epoch 2/75\n",
            "179/179 [==============================] - 21s 118ms/step - loss: 1.8632 - accuracy: 0.2509 - val_loss: 1.8061 - val_accuracy: 0.2514\n",
            "Epoch 3/75\n",
            "179/179 [==============================] - 21s 118ms/step - loss: 1.7632 - accuracy: 0.3098 - val_loss: 1.9136 - val_accuracy: 0.2804\n",
            "Epoch 4/75\n",
            "179/179 [==============================] - 21s 119ms/step - loss: 1.5877 - accuracy: 0.3922 - val_loss: 2.0243 - val_accuracy: 0.2937\n",
            "Epoch 5/75\n",
            "179/179 [==============================] - 21s 116ms/step - loss: 1.4798 - accuracy: 0.4327 - val_loss: 1.6411 - val_accuracy: 0.3562\n",
            "Epoch 6/75\n",
            "179/179 [==============================] - 21s 118ms/step - loss: 1.3917 - accuracy: 0.4688 - val_loss: 1.6003 - val_accuracy: 0.3540\n",
            "Epoch 7/75\n",
            "179/179 [==============================] - 22s 120ms/step - loss: 1.3148 - accuracy: 0.4973 - val_loss: 1.5474 - val_accuracy: 0.4510\n",
            "Epoch 8/75\n",
            "179/179 [==============================] - 21s 118ms/step - loss: 1.2593 - accuracy: 0.5224 - val_loss: 1.5347 - val_accuracy: 0.4325\n",
            "Epoch 9/75\n",
            "179/179 [==============================] - 21s 119ms/step - loss: 1.2031 - accuracy: 0.5460 - val_loss: 1.2995 - val_accuracy: 0.5178\n",
            "Epoch 10/75\n",
            "179/179 [==============================] - 24s 135ms/step - loss: 1.1706 - accuracy: 0.5598 - val_loss: 1.5800 - val_accuracy: 0.4169\n",
            "Epoch 11/75\n",
            "179/179 [==============================] - 21s 118ms/step - loss: 1.1483 - accuracy: 0.5681 - val_loss: 1.3533 - val_accuracy: 0.5249\n",
            "Epoch 12/75\n",
            "179/179 [==============================] - 22s 122ms/step - loss: 1.1064 - accuracy: 0.5856 - val_loss: 1.2908 - val_accuracy: 0.5094\n",
            "Epoch 13/75\n",
            "179/179 [==============================] - 27s 151ms/step - loss: 1.0855 - accuracy: 0.5923 - val_loss: 1.1515 - val_accuracy: 0.5676\n",
            "Epoch 14/75\n",
            "179/179 [==============================] - 21s 117ms/step - loss: 1.0401 - accuracy: 0.6090 - val_loss: 1.3504 - val_accuracy: 0.5426\n",
            "Epoch 15/75\n",
            "179/179 [==============================] - 22s 122ms/step - loss: 1.0195 - accuracy: 0.6189 - val_loss: 1.1199 - val_accuracy: 0.5742\n",
            "Epoch 16/75\n",
            "179/179 [==============================] - 22s 121ms/step - loss: 0.9841 - accuracy: 0.6351 - val_loss: 1.1391 - val_accuracy: 0.5716\n",
            "Epoch 17/75\n",
            "179/179 [==============================] - 22s 121ms/step - loss: 0.9591 - accuracy: 0.6450 - val_loss: 1.1795 - val_accuracy: 0.5753\n",
            "Epoch 18/75\n",
            "179/179 [==============================] - 22s 121ms/step - loss: 0.9441 - accuracy: 0.6458 - val_loss: 1.1397 - val_accuracy: 0.5868\n",
            "Epoch 19/75\n",
            "179/179 [==============================] - 22s 121ms/step - loss: 0.9211 - accuracy: 0.6608 - val_loss: 1.0474 - val_accuracy: 0.6087\n",
            "Epoch 20/75\n",
            "179/179 [==============================] - 22s 122ms/step - loss: 0.8890 - accuracy: 0.6715 - val_loss: 1.4360 - val_accuracy: 0.5220\n",
            "Epoch 21/75\n",
            "179/179 [==============================] - 22s 121ms/step - loss: 0.8746 - accuracy: 0.6805 - val_loss: 1.2182 - val_accuracy: 0.5772\n",
            "Epoch 22/75\n",
            "179/179 [==============================] - 21s 119ms/step - loss: 0.8522 - accuracy: 0.6862 - val_loss: 1.1069 - val_accuracy: 0.6010\n",
            "Epoch 23/75\n",
            "179/179 [==============================] - 21s 118ms/step - loss: 0.7972 - accuracy: 0.7115 - val_loss: 1.2594 - val_accuracy: 0.5666\n",
            "Epoch 24/75\n",
            "179/179 [==============================] - 21s 117ms/step - loss: 0.8011 - accuracy: 0.7065 - val_loss: 1.2874 - val_accuracy: 0.5467\n",
            "Epoch 25/75\n",
            "179/179 [==============================] - 21s 116ms/step - loss: 0.7882 - accuracy: 0.7120 - val_loss: 1.3374 - val_accuracy: 0.5552\n",
            "Epoch 26/75\n",
            "179/179 [==============================] - 21s 117ms/step - loss: 0.7442 - accuracy: 0.7289 - val_loss: 1.2397 - val_accuracy: 0.5850\n",
            "Epoch 27/75\n",
            "179/179 [==============================] - 22s 120ms/step - loss: 0.7166 - accuracy: 0.7416 - val_loss: 1.1958 - val_accuracy: 0.5795\n",
            "Epoch 28/75\n",
            "179/179 [==============================] - 21s 118ms/step - loss: 0.6721 - accuracy: 0.7552 - val_loss: 1.0822 - val_accuracy: 0.6186\n",
            "Epoch 29/75\n",
            "179/179 [==============================] - 21s 117ms/step - loss: 0.6418 - accuracy: 0.7702 - val_loss: 1.3594 - val_accuracy: 0.5565\n",
            "Epoch 30/75\n",
            "179/179 [==============================] - 21s 117ms/step - loss: 0.6262 - accuracy: 0.7749 - val_loss: 1.1465 - val_accuracy: 0.6138\n",
            "Epoch 31/75\n",
            "179/179 [==============================] - 21s 117ms/step - loss: 0.5951 - accuracy: 0.7873 - val_loss: 1.2613 - val_accuracy: 0.6026\n",
            "Epoch 32/75\n",
            "179/179 [==============================] - 21s 117ms/step - loss: 0.5528 - accuracy: 0.8016 - val_loss: 1.2002 - val_accuracy: 0.6042\n",
            "Epoch 33/75\n",
            "179/179 [==============================] - 21s 118ms/step - loss: 0.5248 - accuracy: 0.8114 - val_loss: 1.4729 - val_accuracy: 0.5783\n",
            "Epoch 34/75\n",
            "179/179 [==============================] - 22s 120ms/step - loss: 0.4968 - accuracy: 0.8215 - val_loss: 1.4786 - val_accuracy: 0.5893\n",
            "Epoch 35/75\n",
            "179/179 [==============================] - 21s 118ms/step - loss: 0.4888 - accuracy: 0.8253 - val_loss: 1.4555 - val_accuracy: 0.5716\n",
            "Epoch 36/75\n",
            "179/179 [==============================] - 21s 116ms/step - loss: 0.4497 - accuracy: 0.8421 - val_loss: 1.2818 - val_accuracy: 0.5984\n",
            "Epoch 37/75\n",
            "179/179 [==============================] - 21s 118ms/step - loss: 0.4351 - accuracy: 0.8463 - val_loss: 1.3733 - val_accuracy: 0.5767\n",
            "Epoch 38/75\n",
            "179/179 [==============================] - 22s 121ms/step - loss: 0.4248 - accuracy: 0.8485 - val_loss: 1.3996 - val_accuracy: 0.6147\n",
            "Epoch 39/75\n",
            "179/179 [==============================] - 22s 121ms/step - loss: 0.3977 - accuracy: 0.8599 - val_loss: 1.5538 - val_accuracy: 0.5907\n",
            "Epoch 40/75\n",
            "179/179 [==============================] - 22s 121ms/step - loss: 0.3637 - accuracy: 0.8717 - val_loss: 1.4626 - val_accuracy: 0.6072\n",
            "Epoch 41/75\n",
            "179/179 [==============================] - 22s 122ms/step - loss: 0.3390 - accuracy: 0.8802 - val_loss: 1.8844 - val_accuracy: 0.5627\n",
            "Epoch 42/75\n",
            "179/179 [==============================] - 22s 121ms/step - loss: 0.3166 - accuracy: 0.8894 - val_loss: 1.4427 - val_accuracy: 0.6154\n",
            "Epoch 43/75\n",
            "179/179 [==============================] - 22s 120ms/step - loss: 0.3087 - accuracy: 0.8905 - val_loss: 1.4216 - val_accuracy: 0.6183\n",
            "Epoch 44/75\n",
            "179/179 [==============================] - 22s 121ms/step - loss: 0.2945 - accuracy: 0.8986 - val_loss: 1.7057 - val_accuracy: 0.5785\n",
            "Epoch 45/75\n",
            "179/179 [==============================] - 23s 125ms/step - loss: 0.2912 - accuracy: 0.8978 - val_loss: 1.6690 - val_accuracy: 0.6167\n",
            "Epoch 46/75\n",
            "179/179 [==============================] - 22s 121ms/step - loss: 0.2695 - accuracy: 0.9069 - val_loss: 1.5529 - val_accuracy: 0.6257\n",
            "Epoch 47/75\n",
            "179/179 [==============================] - 21s 117ms/step - loss: 0.2923 - accuracy: 0.8966 - val_loss: 1.5106 - val_accuracy: 0.6296\n",
            "Epoch 48/75\n",
            "179/179 [==============================] - 21s 117ms/step - loss: 0.2600 - accuracy: 0.9099 - val_loss: 1.6271 - val_accuracy: 0.6158\n",
            "Epoch 49/75\n",
            "179/179 [==============================] - 22s 120ms/step - loss: 0.2350 - accuracy: 0.9195 - val_loss: 1.6907 - val_accuracy: 0.6273\n",
            "Epoch 50/75\n",
            "179/179 [==============================] - 21s 117ms/step - loss: 0.2343 - accuracy: 0.9177 - val_loss: 1.6035 - val_accuracy: 0.6337\n",
            "Epoch 51/75\n",
            "179/179 [==============================] - 21s 118ms/step - loss: 0.2182 - accuracy: 0.9231 - val_loss: 1.5879 - val_accuracy: 0.6207\n",
            "Epoch 52/75\n",
            "179/179 [==============================] - 21s 116ms/step - loss: 0.2085 - accuracy: 0.9278 - val_loss: 1.6884 - val_accuracy: 0.6200\n",
            "Epoch 53/75\n",
            "179/179 [==============================] - 22s 122ms/step - loss: 0.2078 - accuracy: 0.9285 - val_loss: 1.7701 - val_accuracy: 0.6046\n",
            "Epoch 54/75\n",
            "179/179 [==============================] - 22s 121ms/step - loss: 0.1969 - accuracy: 0.9332 - val_loss: 1.6853 - val_accuracy: 0.6191\n",
            "Epoch 55/75\n",
            "179/179 [==============================] - 22s 120ms/step - loss: 0.2042 - accuracy: 0.9288 - val_loss: 1.7858 - val_accuracy: 0.5987\n",
            "Epoch 56/75\n",
            "179/179 [==============================] - 22s 121ms/step - loss: 0.1935 - accuracy: 0.9332 - val_loss: 1.6838 - val_accuracy: 0.6289\n",
            "Epoch 57/75\n",
            "179/179 [==============================] - 21s 118ms/step - loss: 0.1804 - accuracy: 0.9362 - val_loss: 2.0464 - val_accuracy: 0.5929\n",
            "Epoch 58/75\n",
            "179/179 [==============================] - 22s 120ms/step - loss: 0.1731 - accuracy: 0.9405 - val_loss: 1.7439 - val_accuracy: 0.6294\n",
            "Epoch 59/75\n",
            "179/179 [==============================] - 22s 121ms/step - loss: 0.1782 - accuracy: 0.9387 - val_loss: 1.7752 - val_accuracy: 0.6140\n",
            "Epoch 60/75\n",
            "179/179 [==============================] - 21s 118ms/step - loss: 0.1825 - accuracy: 0.9389 - val_loss: 1.6282 - val_accuracy: 0.6278\n",
            "Epoch 61/75\n",
            "179/179 [==============================] - 22s 121ms/step - loss: 0.1527 - accuracy: 0.9485 - val_loss: 1.7648 - val_accuracy: 0.6220\n",
            "Epoch 62/75\n",
            "179/179 [==============================] - 21s 118ms/step - loss: 0.1515 - accuracy: 0.9478 - val_loss: 1.7954 - val_accuracy: 0.6254\n",
            "Epoch 63/75\n",
            "179/179 [==============================] - 22s 122ms/step - loss: 0.1424 - accuracy: 0.9512 - val_loss: 1.8005 - val_accuracy: 0.6207\n",
            "Epoch 64/75\n",
            "179/179 [==============================] - 22s 125ms/step - loss: 0.1511 - accuracy: 0.9502 - val_loss: 1.8899 - val_accuracy: 0.6206\n",
            "Epoch 65/75\n",
            "179/179 [==============================] - 21s 117ms/step - loss: 0.1447 - accuracy: 0.9501 - val_loss: 1.7825 - val_accuracy: 0.6266\n",
            "Epoch 66/75\n",
            "179/179 [==============================] - 21s 119ms/step - loss: 0.1416 - accuracy: 0.9515 - val_loss: 1.8377 - val_accuracy: 0.6310\n",
            "Epoch 67/75\n",
            "179/179 [==============================] - 22s 123ms/step - loss: 0.1295 - accuracy: 0.9563 - val_loss: 1.8543 - val_accuracy: 0.6250\n",
            "Epoch 68/75\n",
            "179/179 [==============================] - 21s 119ms/step - loss: 0.1227 - accuracy: 0.9588 - val_loss: 1.8440 - val_accuracy: 0.6358\n",
            "Epoch 69/75\n",
            "179/179 [==============================] - 21s 117ms/step - loss: 0.1251 - accuracy: 0.9579 - val_loss: 1.9560 - val_accuracy: 0.6255\n",
            "Epoch 70/75\n",
            "179/179 [==============================] - 22s 122ms/step - loss: 0.1197 - accuracy: 0.9609 - val_loss: 1.9784 - val_accuracy: 0.6218\n",
            "Epoch 71/75\n",
            "179/179 [==============================] - 21s 117ms/step - loss: 0.1195 - accuracy: 0.9599 - val_loss: 2.0156 - val_accuracy: 0.6179\n",
            "Epoch 72/75\n",
            "179/179 [==============================] - 21s 118ms/step - loss: 0.1270 - accuracy: 0.9565 - val_loss: 1.8775 - val_accuracy: 0.6303\n",
            "Epoch 73/75\n",
            "179/179 [==============================] - 22s 122ms/step - loss: 0.1368 - accuracy: 0.9549 - val_loss: 1.8605 - val_accuracy: 0.6371\n",
            "Epoch 74/75\n",
            "179/179 [==============================] - 22s 121ms/step - loss: 0.1253 - accuracy: 0.9587 - val_loss: 1.9465 - val_accuracy: 0.6138\n",
            "Epoch 75/75\n",
            "179/179 [==============================] - 22s 122ms/step - loss: 0.1467 - accuracy: 0.9512 - val_loss: 1.7757 - val_accuracy: 0.6289\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save('/content/drive/MyDrive/models/mau.h5')"
      ],
      "metadata": {
        "id": "PsQvoSA_IZZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "# Load the saved model\n",
        "model_path = '/content/drive/MyDrive/models/mau.h5'\n",
        "loaded_model = load_model(model_path)\n",
        "print(\"Model loaded from Google Drive.\")"
      ],
      "metadata": {
        "id": "BcwVbTdccExo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a6a00e6-0ead-471c-feba-72bf3a52c9ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Model loaded from Google Drive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get model Summary"
      ],
      "metadata": {
        "id": "jalNdJRkyUR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "model_path = '/content/drive/My Drive/models/mau.h5'\n",
        "model = load_model(model_path)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vTgXMeEyQsv",
        "outputId": "74108402-87fd-4615-c376-fae611690fcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_4 (Conv1D)           (None, 182, 256)          1536      \n",
            "                                                                 \n",
            " max_pooling1d_4 (MaxPoolin  (None, 91, 256)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_5 (Conv1D)           (None, 91, 256)           327936    \n",
            "                                                                 \n",
            " max_pooling1d_5 (MaxPoolin  (None, 46, 256)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_6 (Conv1D)           (None, 46, 128)           163968    \n",
            "                                                                 \n",
            " max_pooling1d_6 (MaxPoolin  (None, 23, 128)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 23, 128)           0         \n",
            "                                                                 \n",
            " conv1d_7 (Conv1D)           (None, 23, 128)           82048     \n",
            "                                                                 \n",
            " conv1d_8 (Conv1D)           (None, 23, 128)           82048     \n",
            "                                                                 \n",
            " conv1d_9 (Conv1D)           (None, 23, 128)           82048     \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 23, 128)           512       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " activation (Activation)     (None, 23, 128)           0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 23, 128)           0         \n",
            "                                                                 \n",
            " conv1d_10 (Conv1D)          (None, 23, 64)            41024     \n",
            "                                                                 \n",
            " conv1d_11 (Conv1D)          (None, 23, 64)            20544     \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 1472)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 4096)              6033408   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 8)                 32776     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23649160 (90.21 MB)\n",
            "Trainable params: 23648904 (90.21 MB)\n",
            "Non-trainable params: 256 (1.00 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Evaluation"
      ],
      "metadata": {
        "id": "rnJOmYhZybFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "loss, accuracy = loaded_model.evaluate(x_test, y_test)\n",
        "\n",
        "y_pred = loaded_model.predict(x_test)\n",
        "y_pred_classes = y_pred.argmax(axis=1)\n",
        "y_true = y_test.argmax(axis=1)\n",
        "\n",
        "precision = precision_score(y_true, y_pred_classes, average='weighted')\n",
        "recall = recall_score(y_true, y_pred_classes, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred_classes, average='weighted')\n",
        "\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "PNu4SgNKIZMu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4db804c5-8a6b-44e6-e305-a63bc9dee8ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 2.2512\n",
            "Test Accuracy: 62.23%\n",
            "113/113 [==============================] - 3s 25ms/step\n",
            "Precision: 0.6226\n",
            "Recall: 0.6223\n",
            "F1 Score: 0.6208\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "model_path = '/content/drive/My Drive/model/mau.h5'\n",
        "\n",
        "model = load_model(model_path)\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gvXWGvjwATin",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 753
        },
        "outputId": "d2ee56b6-9ee9-4588-c555-4dee2f401796"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "8/8 [==============================] - 1s 90ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Scaler file"
      ],
      "metadata": {
        "id": "W7iMb2tFw7K_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import librosa.display\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pickle\n",
        "\n",
        "from google.colab import drive\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to the zip file in your Google Drive containing only audio files\n",
        "zip_file_path = '/content/drive/MyDrive/ravdess.zip'\n",
        "import zipfile\n",
        "\n",
        "# Directory to extract the audio dataset\n",
        "extract_dir = '/content/MyDrive/RAVDESS/ravdess'\n",
        "# Unzip the audio dataset\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "# Directory to the audio dataset\n",
        "Ravdess = '/content/MyDrive/RAVDESS/ravdess/ravdess'\n",
        "\n",
        "# List directories and files\n",
        "ravdess_directory_list = os.listdir(Ravdess)\n",
        "file_emotion = []\n",
        "file_path = []\n",
        "\n",
        "# Extract emotions and file paths\n",
        "for dir in ravdess_directory_list:\n",
        "    actor = os.listdir(os.path.join(Ravdess, dir))\n",
        "    for file in actor:\n",
        "        part = file.split('.')[0].split('-')\n",
        "        file_emotion.append(int(part[2]))\n",
        "        file_path.append(os.path.join(Ravdess, dir, file))\n",
        "\n",
        "# Create DataFrames\n",
        "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
        "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
        "ravdess_df = pd.concat([emotion_df, path_df], axis=1)\n",
        "\n",
        "# Map emotions to their respective labels\n",
        "emotion_map = {1: 'neutral', 2: 'calm', 3: 'happy', 4: 'sad', 5: 'angry', 6: 'fear', 7: 'disgust', 8: 'surprise'}\n",
        "ravdess_df.Emotions.replace(emotion_map, inplace=True)\n",
        "\n",
        "# Filter out 'calm' emotion\n",
        "ravdess_df = ravdess_df[ravdess_df.Emotions != 'calm']\n",
        "\n",
        "def extract_features(data, sample_rate):\n",
        "    result = np.array([])\n",
        "\n",
        "    # Zero Crossing Rate\n",
        "    zcr = np.mean(librosa.feature.zero_crossing_rate(y=data).T, axis=0)\n",
        "    result = np.hstack((result, zcr))\n",
        "\n",
        "    # Chroma Shift\n",
        "    stft = np.abs(librosa.stft(data))\n",
        "    chroma_stft = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n",
        "    result = np.hstack((result, chroma_stft))\n",
        "\n",
        "    # MFCC\n",
        "    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
        "    result = np.hstack((result, mfcc))\n",
        "\n",
        "    # Root Mean Square Value\n",
        "    rms = np.mean(librosa.feature.rms(y=data).T, axis=0)\n",
        "    result = np.hstack((result, rms))\n",
        "\n",
        "    # MelSpectrogram\n",
        "    mel = np.mean(librosa.feature.melspectrogram(y=data, sr=sample_rate).T, axis=0)\n",
        "    result = np.hstack((result, mel))\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "x, y = [], []\n",
        "\n",
        "for path, emotion in zip(ravdess_df.Path, ravdess_df.Emotions):\n",
        "    data, sample_rate = librosa.load(path, res_type='kaiser_fast')\n",
        "\n",
        "    features = extract_features(data, sample_rate)\n",
        "\n",
        "    x.append(features)\n",
        "    y.append(emotion)\n",
        "\n",
        "x = np.array(x)\n",
        "y = np.array(y)\n",
        "\n",
        "# Normalize the feature data\n",
        "scaler = StandardScaler()\n",
        "x = scaler.fit_transform(x)\n",
        "\n",
        "scaler_path = '/content/drive/MyDrive/audio_scaler.pkl'\n",
        "with open(scaler_path, 'wb') as f:\n",
        "    pickle.dump(scaler, f)\n",
        "\n",
        "print(f'Scaler saved to {scaler_path}')\n"
      ],
      "metadata": {
        "id": "RUaUR2MEAXxQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f9a5f44-f83e-4e47-9d55-ba8930ea2ad8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Scaler saved to /content/drive/MyDrive/audio_scaler.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the model\n"
      ],
      "metadata": {
        "id": "GVI-ipMpyzjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "model_path = '/content/drive/My Drive/models/mau.h5'\n",
        "model = load_model(model_path)"
      ],
      "metadata": {
        "id": "QN7l1Cn9wY6t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24a57c3d-3172-4329-d356-5fcbe4316474"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#testing\n",
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import load_model\n",
        "import pickle\n",
        "from google.colab import drive\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to the trained model and scaler\n",
        "model_path = '/content/drive/MyDrive/models/mau.h5'\n",
        "scaler_path = '/content/drive/MyDrive/audio_scaler.pkl'\n",
        "\n",
        "# Load the trained classifier\n",
        "def load_classifier(model_path, scaler_path):\n",
        "    with open(scaler_path, 'rb') as f:\n",
        "        scaler = pickle.load(f)\n",
        "    classifier = load_model(model_path)\n",
        "    return scaler, classifier\n",
        "\n",
        "# Extract audio features by segment\n",
        "def extract_features_segment(audio_segment, sample_rate):\n",
        "    result = np.array([])\n",
        "\n",
        "    # Zero Crossing Rate\n",
        "    zcr = np.mean(librosa.feature.zero_crossing_rate(y=audio_segment).T, axis=0)\n",
        "    result = np.hstack((result, zcr))\n",
        "\n",
        "    # Chroma Shift\n",
        "    stft = np.abs(librosa.stft(audio_segment))\n",
        "    chroma_stft = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n",
        "    result = np.hstack((result, chroma_stft))\n",
        "\n",
        "    # MFCC\n",
        "    mfcc = np.mean(librosa.feature.mfcc(y=audio_segment, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
        "    result = np.hstack((result, mfcc))\n",
        "\n",
        "    # Root Mean Square Value\n",
        "    rms = np.mean(librosa.feature.rms(y=audio_segment).T, axis=0)\n",
        "    result = np.hstack((result, rms))\n",
        "\n",
        "    # MelSpectrogram\n",
        "    mel = np.mean(librosa.feature.melspectrogram(y=audio_segment, sr=sample_rate).T, axis=0)\n",
        "    result = np.hstack((result, mel))\n",
        "\n",
        "    return result\n",
        "\n",
        "# Predict sentiment\n",
        "def predict_sentiment(audio_file, scaler, classifier, sample_rate=22050):\n",
        "\n",
        "    emotions = ['neutral', 'happy', 'sad', 'angry', 'fear', 'disgust', 'surprise']\n",
        "    audio, _ = librosa.load(audio_file, sr=sample_rate)\n",
        "    segments = librosa.effects.split(audio, top_db=20)\n",
        "    segment_sentiments = []\n",
        "    overall_sentiments = []\n",
        "\n",
        "    for start, end in segments:\n",
        "        start_ms = int((start / sample_rate) * 1000)\n",
        "        end_ms = int((end / sample_rate) * 1000)\n",
        "        segment = audio[start:end]\n",
        "        features = extract_features_segment(segment, sample_rate)\n",
        "\n",
        "        features_scaled = scaler.transform(features.reshape(1, -1))\n",
        "        sentiment = classifier.predict(features_scaled)[0]\n",
        "        sentiment_label = emotions[np.argmax(sentiment)]\n",
        "        segment_sentiments.append((start_ms, end_ms, sentiment_label))\n",
        "\n",
        "    if segment_sentiments:\n",
        "        current_start, current_end, current_sentiment = segment_sentiments[0]\n",
        "        for next_start, next_end, next_sentiment in segment_sentiments[1:]:\n",
        "            if next_sentiment == current_sentiment:\n",
        "                current_end = next_end\n",
        "            else:\n",
        "                overall_sentiments.append((current_start, current_end, current_sentiment))\n",
        "                current_start, current_end, current_sentiment = next_start, next_end, next_sentiment\n",
        "        overall_sentiments.append((current_start, current_end, current_sentiment))\n",
        "\n",
        "    return overall_sentiments\n",
        "\n",
        "scaler, classifier = load_classifier(model_path, scaler_path)\n",
        "audio_file_path = '/content/drive/MyDrive/AudioData/disgust/03-01-07-01-01-01-11.wav'\n",
        "sentiments = predict_sentiment(audio_file_path, scaler, classifier)\n",
        "print(sentiments)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8ZQBBW_jV1T",
        "outputId": "da1e1419-01fb-4d94-c814-52d9d2c0b610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "1/1 [==============================] - 0s 154ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "[(1044, 2275, 'angry'), (2321, 2693, 'disgust')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the sentiment of audio in frame wise"
      ],
      "metadata": {
        "id": "kVbIyUVrlfoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import load_model\n",
        "import pickle\n",
        "from google.colab import drive\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "model_path = '/content/drive/MyDrive/models/mau.h5'\n",
        "scaler_path = '/content/drive/MyDrive/audio_scaler.pkl'\n",
        "\n",
        "# Load the trained classifier\n",
        "def load_classifier(model_path, scaler_path):\n",
        "    with open(scaler_path, 'rb') as f:\n",
        "        scaler = pickle.load(f)\n",
        "    classifier = load_model(model_path)\n",
        "    return scaler, classifier\n",
        "\n",
        "# Extract audio features by segment\n",
        "def extract_features_segment(audio_segment, sample_rate):\n",
        "    result = np.array([])\n",
        "\n",
        "    # Zero Crossing Rate\n",
        "    zcr = np.mean(librosa.feature.zero_crossing_rate(y=audio_segment).T, axis=0)\n",
        "    result = np.hstack((result, zcr))\n",
        "\n",
        "    # Chroma Shift\n",
        "    stft = np.abs(librosa.stft(audio_segment))\n",
        "    chroma_stft = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n",
        "    result = np.hstack((result, chroma_stft))\n",
        "\n",
        "    # MFCC\n",
        "    mfcc = np.mean(librosa.feature.mfcc(y=audio_segment, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
        "    result = np.hstack((result, mfcc))\n",
        "\n",
        "    # Root Mean Square Value\n",
        "    rms = np.mean(librosa.feature.rms(y=audio_segment).T, axis=0)\n",
        "    result = np.hstack((result, rms))\n",
        "\n",
        "    # MelSpectrogram\n",
        "    mel = np.mean(librosa.feature.melspectrogram(y=audio_segment, sr=sample_rate).T, axis=0)\n",
        "    result = np.hstack((result, mel))\n",
        "\n",
        "    return result\n",
        "\n",
        "# Predict sentiment\n",
        "def predict_sentiment(audio_file, scaler, classifier, sample_rate=22050):\n",
        "    emotions = ['neutral', 'happy', 'sad', 'angry', 'fearful', 'disgust', 'surprised']\n",
        "    audio, _ = librosa.load(audio_file, sr=sample_rate)\n",
        "    duration = librosa.get_duration(y=audio, sr=sample_rate)\n",
        "    total_seconds = int(np.ceil(duration))\n",
        "    sentiments = []\n",
        "\n",
        "    for second in range(total_seconds):\n",
        "        start_sample = second * sample_rate\n",
        "        end_sample = start_sample + sample_rate\n",
        "\n",
        "        if end_sample > len(audio):\n",
        "            end_sample = len(audio)\n",
        "\n",
        "        segment = audio[start_sample:end_sample]\n",
        "\n",
        "        if len(segment) > 0:\n",
        "            features = extract_features_segment(segment, sample_rate)\n",
        "            features_scaled = scaler.transform(features.reshape(1, -1))\n",
        "            sentiment = classifier.predict(features_scaled)[0]\n",
        "            sentiment_label = emotions[np.argmax(sentiment)]\n",
        "        else:\n",
        "            sentiment_label = None\n",
        "\n",
        "        sentiments.append(sentiment_label)\n",
        "\n",
        "    return sentiments, duration\n",
        "\n",
        "# Load classifier and scaler\n",
        "scaler, classifier = load_classifier(model_path, scaler_path)\n",
        "\n",
        "# Path to the audio file in your Google Drive\n",
        "audio_file_path = '/content/drive/MyDrive/AudioData/disgust/03-01-07-01-01-01-11.wav'\n",
        "\n",
        "# Predict sentiments\n",
        "sentiments, duration = predict_sentiment(audio_file_path, scaler, classifier)\n",
        "\n",
        "# Print results\n",
        "print(\"Duration of the audio file:\", duration, \"seconds\")\n",
        "print(\"Sentiments:\", sentiments)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPk_c8-VjVaQ",
        "outputId": "2421b996-4953-4c94-f608-9ff73adcd0d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "1/1 [==============================] - 0s 136ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Duration of the audio file: 3.670340136054422 seconds\n",
            "Sentiments: ['disgust', 'angry', 'disgust', 'disgust']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import load_model\n",
        "import pickle\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Paths to the trained model and scaler\n",
        "model_path = '/content/drive/MyDrive/models/mau.h5'\n",
        "scaler_path = '/content/drive/MyDrive/audio_scaler.pkl'\n",
        "\n",
        "# Load the trained classifier\n",
        "def load_classifier(model_path, scaler_path):\n",
        "    with open(scaler_path, 'rb') as f:\n",
        "        scaler = pickle.load(f)\n",
        "    classifier = load_model(model_path)\n",
        "    return scaler, classifier\n",
        "\n",
        "# Extract audio features by segment\n",
        "def extract_features_segment(audio_segment, sample_rate):\n",
        "    result = np.array([])\n",
        "\n",
        "    # Zero Crossing Rate\n",
        "    zcr = np.mean(librosa.feature.zero_crossing_rate(y=audio_segment).T, axis=0)\n",
        "    result = np.hstack((result, zcr))\n",
        "\n",
        "    # Chroma Shift\n",
        "    stft = np.abs(librosa.stft(audio_segment))\n",
        "    chroma_stft = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n",
        "    result = np.hstack((result, chroma_stft))\n",
        "\n",
        "    # MFCC\n",
        "    mfcc = np.mean(librosa.feature.mfcc(y=audio_segment, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
        "    result = np.hstack((result, mfcc))\n",
        "\n",
        "    # Root Mean Square Value\n",
        "    rms = np.mean(librosa.feature.rms(y=audio_segment).T, axis=0)\n",
        "    result = np.hstack((result, rms))\n",
        "\n",
        "    # MelSpectrogram\n",
        "    mel = np.mean(librosa.feature.melspectrogram(y=audio_segment, sr=sample_rate).T, axis=0)\n",
        "    result = np.hstack((result, mel))\n",
        "\n",
        "    return result\n",
        "\n",
        "# Predict sentiment\n",
        "def predict_sentiment(audio_file, scaler, classifier, sample_rate=22050):\n",
        "    emotions = ['neutral', 'happy', 'sad', 'angry', 'fearful', 'disgust', 'surprised']\n",
        "    audio, _ = librosa.load(audio_file, sr=sample_rate)\n",
        "    duration = librosa.get_duration(y=audio, sr=sample_rate)\n",
        "    total_seconds = int(np.ceil(duration))\n",
        "    sentiments = []\n",
        "\n",
        "    previous_sentiment_label = None\n",
        "\n",
        "    for second in range(total_seconds):\n",
        "        start_sample = second * sample_rate\n",
        "        end_sample = start_sample + sample_rate\n",
        "\n",
        "        if end_sample > len(audio):\n",
        "            end_sample = len(audio)\n",
        "\n",
        "        segment = audio[start_sample:end_sample]\n",
        "\n",
        "        if len(segment) > 0:\n",
        "            features = extract_features_segment(segment, sample_rate)\n",
        "            features_scaled = scaler.transform(features.reshape(1, -1))\n",
        "            sentiment = classifier.predict(features_scaled)[0]\n",
        "            sentiment_label = emotions[np.argmax(sentiment)]\n",
        "            previous_sentiment_label = sentiment_label\n",
        "        else:\n",
        "            sentiment_label = previous_sentiment_label\n",
        "\n",
        "        sentiments.append(sentiment_label)\n",
        "\n",
        "    return sentiments, duration\n",
        "\n",
        "# Load classifier and scaler\n",
        "scaler, classifier = load_classifier(model_path, scaler_path)\n",
        "\n",
        "# Path to the audio file in your Google Drive\n",
        "audio_file_path = '/content/drive/MyDrive/AudioData/disgust/03-01-07-01-01-01-11.wav'\n",
        "\n",
        "# Predict sentiments\n",
        "sentiments, duration = predict_sentiment(audio_file_path, scaler, classifier)\n",
        "\n",
        "# Print results\n",
        "print(\"Duration of the audio file:\", duration, \"seconds\")\n",
        "print(\"Sentiments:\", sentiments)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUS7leCrVdjE",
        "outputId": "169838f0-e089-4291-e568-28d0f387c031"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7e4c725972e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 172ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Duration of the audio file: 3.670340136054422 seconds\n",
            "Sentiments: ['disgust', 'angry', 'disgust', 'disgust']\n"
          ]
        }
      ]
    }
  ]
}